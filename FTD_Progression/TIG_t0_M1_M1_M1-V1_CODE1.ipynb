{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "LDp-m__TEfAs"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "y1zYaVzSEbmO"
   },
   "outputs": [],
   "source": [
    "seed_value = 21\n",
    "np.random.seed(seed_value)\n",
    "random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "PErfwgV42om0"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# To list available GPUs\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Set memory growth to avoid allocating all the GPU memory at once\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        \n",
    "        # Set TensorFlow to use only the first GPU (if you have more than one)\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "        print(f\"Using GPU: {gpus[0].name}\")\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "# Your TensorFlow code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "5uwMKtNs30J4"
   },
   "outputs": [],
   "source": [
    "os.makedirs(\"Tig_ftd_time_series_data_txt\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "vclXjmJF2xKK"
   },
   "outputs": [],
   "source": [
    "files= [file1 for file1 in os.listdir(\"Test2_Version2/ftd_rep1_v2_txt_version2\") if file1.endswith('.txt')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v-_X9blT32P9",
    "outputId": "7da97c83-7846-439c-d6a5-2f0f8c3191eb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1148"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gr5BsROU_duh"
   },
   "source": [
    "## Now we need to build a model - M1 (LSTM, GRUs, Simple-Rnn) Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "RduNXkQ8kKIY"
   },
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "E3FsQq4YRUs8"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_excel(\"ftd_temporal_processed.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 412
    },
    "id": "tVqqliiJRUqL",
    "outputId": "a39fed1e-4188-4589-a8fc-6dc800103183"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>CDR_LANG</th>\n",
       "      <th>CDR_BEHAV</th>\n",
       "      <th>CDR_TOT</th>\n",
       "      <th>CDR_BOX_SCORE</th>\n",
       "      <th>MMSE_TOT</th>\n",
       "      <th>TRCOTOT</th>\n",
       "      <th>CORR10</th>\n",
       "      <th>INTR10</th>\n",
       "      <th>...</th>\n",
       "      <th>NPI_DISN</th>\n",
       "      <th>NPI_IRR</th>\n",
       "      <th>NPI_MOT</th>\n",
       "      <th>NPI_NITE</th>\n",
       "      <th>NPI_APP</th>\n",
       "      <th>FAQ_TAXES</th>\n",
       "      <th>FAQ_MEALPREP</th>\n",
       "      <th>FAQ_EVENTS</th>\n",
       "      <th>FAQ_PAYATTN</th>\n",
       "      <th>FAQ_REMDATES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>subject_1_timestamp_0</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>subject_1_timestamp_1</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>subject_1_timestamp_2</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>subject_1_timestamp_3</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>subject_2_timestamp_0</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.40625</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>subject_2_timestamp_1</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.40625</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>subject_2_timestamp_2</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.68750</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>subject_2_timestamp_3</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.75000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>subject_3_timestamp_0</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.31250</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>subject_3_timestamp_1</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.46875</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      ID  EDUCATION  CDR_LANG  CDR_BEHAV   CDR_TOT  \\\n",
       "0  subject_1_timestamp_0   0.066667  0.000000   0.000000  0.000000   \n",
       "1  subject_1_timestamp_1   0.066667  0.000000   0.000000  0.000000   \n",
       "2  subject_1_timestamp_2   0.066667  0.000000   0.000000  0.000000   \n",
       "3  subject_1_timestamp_3   0.066667  0.000000   0.000000  0.000000   \n",
       "4  subject_2_timestamp_0   0.044444  0.166667   0.666667  0.333333   \n",
       "5  subject_2_timestamp_1   0.044444  0.166667   0.666667  0.333333   \n",
       "6  subject_2_timestamp_2   0.044444  0.666667   0.666667  0.666667   \n",
       "7  subject_2_timestamp_3   0.044444  0.666667   0.333333  0.666667   \n",
       "8  subject_3_timestamp_0   0.033333  0.666667   0.666667  0.166667   \n",
       "9  subject_3_timestamp_1   0.033333  0.333333   1.000000  0.333333   \n",
       "\n",
       "   CDR_BOX_SCORE  MMSE_TOT   TRCOTOT    CORR10    INTR10  ...  NPI_DISN  \\\n",
       "0        0.00000  1.000000  0.000000  0.000000  0.000000  ...         0   \n",
       "1        0.00000  1.000000  0.861111  0.777778  0.000000  ...         0   \n",
       "2        0.00000  1.000000  0.777778  0.666667  0.111111  ...         0   \n",
       "3        0.00000  1.000000  0.861111  1.000000  0.000000  ...         0   \n",
       "4        0.40625  0.966667  0.000000  0.000000  0.000000  ...         1   \n",
       "5        0.40625  0.966667  0.000000  0.000000  0.000000  ...         1   \n",
       "6        0.68750  0.733333  0.666667  0.000000  0.000000  ...         1   \n",
       "7        0.75000  0.733333  0.666667  0.000000  0.000000  ...         1   \n",
       "8        0.31250  0.966667  0.777778  0.555556  0.000000  ...         1   \n",
       "9        0.46875  1.000000  0.583333  0.000000  0.000000  ...         1   \n",
       "\n",
       "   NPI_IRR  NPI_MOT  NPI_NITE  NPI_APP  FAQ_TAXES  FAQ_MEALPREP  FAQ_EVENTS  \\\n",
       "0        0        0  0.000000        0      0.000         0.000       0.000   \n",
       "1        0        0  0.000000        0      0.000         0.000       0.000   \n",
       "2        0        0  0.000000        0      0.000         0.000       0.000   \n",
       "3        0        0  0.000000        0      0.000         0.000       0.000   \n",
       "4        0        1  0.000000        1      0.375         0.375       0.125   \n",
       "5        0        1  0.000000        1      0.375         0.375       0.125   \n",
       "6        0        1  0.111111        0      0.375         0.375       0.375   \n",
       "7        0        1  0.111111        0      0.375         0.375       0.375   \n",
       "8        1        0  0.000000        0      0.250         0.000       0.125   \n",
       "9        1        1  0.000000        1      0.375         0.250       0.125   \n",
       "\n",
       "   FAQ_PAYATTN  FAQ_REMDATES  \n",
       "0     0.000000      0.000000  \n",
       "1     0.000000      0.000000  \n",
       "2     0.000000      0.000000  \n",
       "3     0.000000      0.000000  \n",
       "4     0.111111      0.333333  \n",
       "5     0.111111      0.333333  \n",
       "6     0.333333      1.000000  \n",
       "7     0.333333      1.000000  \n",
       "8     0.111111      0.666667  \n",
       "9     0.222222      1.000000  \n",
       "\n",
       "[10 rows x 37 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XizKYOx6V-Fj",
    "outputId": "fdbd7c1f-8a84-4f94-944f-3540d1a6ea2a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1148, 37)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FzF21_ciRUm6",
    "outputId": "8ac58411-3321-48ea-80a5-b10d3ffe0158"
   },
   "outputs": [],
   "source": [
    "X=[]\n",
    "y=[]\n",
    "for i in range(287):\n",
    "  y1=[]\n",
    "  y1.append(i*4+0)\n",
    "  y1.append(i*4+1)\n",
    "  y1.append(i*4+2)\n",
    "  y1.append(i*4+3)\n",
    "#   print(y1)\n",
    "  for j in range(len(y1)-1):\n",
    "    x1=df.iloc[y1[j]]\n",
    "    # print(x1)\n",
    "    # print(x1.index)\n",
    "    ind1=x1['ID']\n",
    "#     print(ind1)\n",
    "    y2=df.iloc[y1[j+1]]\n",
    "    ind2=y2['ID']\n",
    "    X.append(ind1)\n",
    "    y.append(ind2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F-9v7awYdgSk",
    "outputId": "9fd611a2-0129-4be3-90f4-2b93e3bf3027"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "861"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LU1gRIdRRUj9",
    "outputId": "2d4daa9a-cd82-4706-c1cd-193e33506e08"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "861"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "zVrVldam9MNa"
   },
   "outputs": [],
   "source": [
    "l1=[1,2,3,4,5,6,7,8,9,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ye5vLHTMRUgo",
    "outputId": "aa27e9fb-8614-4a37-91c1-efb1ee25e99c"
   },
   "outputs": [],
   "source": [
    "img_x=[]\n",
    "for i in X:\n",
    "  s=\"Test2_Version2/ftd_rep1_v2_txt_version2/_\"+i+\"_data.txt\"\n",
    "  img=np.loadtxt(s)\n",
    "#   print(s)\n",
    "  img_x.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g-K_yvd9RUUF",
    "outputId": "a13965c1-aeba-4000-a90f-0b7cacbcbc85"
   },
   "outputs": [],
   "source": [
    "img_y=[]\n",
    "for i in y:\n",
    "  s=\"Test2_Version2/ftd_rep1_v2_txt_version2/_\"+i+\"_data.txt\"\n",
    "  img=np.loadtxt(s)\n",
    "#   print(s)\n",
    "  img_y.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Zm8rZ-lObCpY"
   },
   "outputs": [],
   "source": [
    "X_train=[]\n",
    "y_train=[]\n",
    "X_test=[]\n",
    "y_test=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "JdSBNlEYbOm_"
   },
   "outputs": [],
   "source": [
    "count=0\n",
    "for i in img_x:\n",
    "  if(count<687):\n",
    "    X_train.append(i)\n",
    "  else:\n",
    "    X_test.append(i)\n",
    "  count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "drVMznpWbtBG"
   },
   "outputs": [],
   "source": [
    "count=0\n",
    "for i in img_y:\n",
    "  if(count<687):\n",
    "    y_train.append(i)\n",
    "  else:\n",
    "    y_test.append(i)\n",
    "  count+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SuE1sTCobxM9",
    "outputId": "c513c0f2-e1f2-43e4-b275-3cb102550754"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "0ANz4oxTANcZ"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "selected_indices = random.sample(range(len(X_train)), 229)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((687, 71, 142), (687, 71, 142))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((174, 71, 142), (174, 71, 142))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "dqPp4W-bBeQ7"
   },
   "outputs": [],
   "source": [
    "s_X_train = [X_train[i] for i in selected_indices]\n",
    "s_y_train = [y_train[i] for i in selected_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "jhfqLa2MBnRQ"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "selected_indices = random.sample(range(len(X_test)), 58)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "CVoKQsiEBssU"
   },
   "outputs": [],
   "source": [
    "s_X_test = [X_test[i] for i in selected_indices]\n",
    "s_y_test = [y_test[i] for i in selected_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "qvps7m5hbyX6"
   },
   "outputs": [],
   "source": [
    "X_train=np.array(X_train)\n",
    "y_train=np.array(y_train)\n",
    "X_test=np.array(X_test)\n",
    "y_test=np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "Jd-cj_vbBysE"
   },
   "outputs": [],
   "source": [
    "s_X_train=np.array(s_X_train)\n",
    "s_y_train=np.array(s_y_train)\n",
    "s_X_test=np.array(s_X_test)\n",
    "s_y_test=np.array(s_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HFkhjnH2ci9z",
    "outputId": "f17329c7-92f3-45b9-c53b-c4263bc5125a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(229, 71, 142)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IGgFQHGmcYNA",
    "outputId": "5cc0434e-267e-4bc0-cbbe-ce0e97083374"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58, 71, 142)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "UsY81-8ecLkN"
   },
   "outputs": [],
   "source": [
    "X_test=X_test.reshape((174,1,71,142))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "rBemFEE5CEK8"
   },
   "outputs": [],
   "source": [
    "s_X_test=s_X_test.reshape((58,1,71,142))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "T-OkOzQ7dJGD"
   },
   "outputs": [],
   "source": [
    "X_train=X_train.reshape((687,1,71,142))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "-39eoicpCJwf"
   },
   "outputs": [],
   "source": [
    "s_X_train=s_X_train.reshape((229,1,71,142))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "nnwupLbCdPxS"
   },
   "outputs": [],
   "source": [
    "y_test=y_test.reshape((174, 71*142))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "txGOI3iPCO2D"
   },
   "outputs": [],
   "source": [
    "s_y_test=s_y_test.reshape((58, 71*142))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "-vfQZ7yAdvhn"
   },
   "outputs": [],
   "source": [
    "y_train=y_train.reshape((687, 71*142))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "VOXH1Gy8CTWk"
   },
   "outputs": [],
   "source": [
    "s_y_train=s_y_train.reshape((229, 71*142))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((687, 1, 71, 142), (687, 10082))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((174, 1, 71, 142), (174, 10082))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "rNmg4Ey1elC0"
   },
   "outputs": [],
   "source": [
    "X_train=X_train/255.0\n",
    "X_test=X_test/255.0\n",
    "y_test=y_test/255.0\n",
    "y_train=y_train/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "u55Zf7-ECY7D"
   },
   "outputs": [],
   "source": [
    "s_X_train=s_X_train/255.0\n",
    "s_X_test=s_X_test/255.0\n",
    "s_y_test=s_y_test/255.0\n",
    "s_y_train=s_y_train/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import ConvLSTM2D, Flatten, Dense, BatchNormalization, Dropout, Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.reshape(-1, 71, 142)\n",
    "y_test = y_test.reshape(-1, 71, 142)\n",
    "X_train = X_train.reshape(-1, 1, 71, 142, 1)\n",
    "X_test = X_test.reshape(-1, 1, 71, 142, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-02 10:48:37.805205: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv_lstm2d (ConvLSTM2D)    (None, 1, 69, 140, 32)    38144     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 1, 69, 140, 32)   128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv_lstm2d_1 (ConvLSTM2D)  (None, 67, 138, 32)       73856     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 67, 138, 32)      128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 295872)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10082)             2982991586\n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 71, 142)           0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,983,103,842\n",
      "Trainable params: 2,983,103,714\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_m1 = Sequential()\n",
    "\n",
    "# Adding ConvLSTM2D layers\n",
    "model_m1.add(ConvLSTM2D(filters=32, kernel_size=(3, 3), activation='relu', \n",
    "                      input_shape=(1, 71, 142, 1), return_sequences=True))\n",
    "model_m1.add(BatchNormalization())\n",
    "\n",
    "model_m1.add(ConvLSTM2D(filters=32, kernel_size=(3, 3), activation='relu'))\n",
    "model_m1.add(BatchNormalization())\n",
    "\n",
    "# Flattening the output\n",
    "model_m1.add(Flatten())\n",
    "\n",
    "# Adding a Dense layer\n",
    "model_m1.add(Dense(71 * 142, activation='relu'))\n",
    "\n",
    "# Reshape to the target shape (71, 142)\n",
    "model_m1.add(Reshape((71, 142)))\n",
    "\n",
    "# Compiling the model\n",
    "model_m1.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "model_m1.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lJlCd7sPee11",
    "outputId": "44373d17-fd95-4473-a25b-5442f11bdb5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "22/22 [==============================] - 358s 15s/step - loss: 0.3463\n",
      "Epoch 2/20\n",
      "22/22 [==============================] - 330s 15s/step - loss: 0.0231\n",
      "Epoch 3/20\n",
      "22/22 [==============================] - 330s 15s/step - loss: 0.0229\n",
      "Epoch 4/20\n",
      "22/22 [==============================] - 335s 15s/step - loss: 0.0229\n",
      "Epoch 5/20\n",
      "22/22 [==============================] - 320s 15s/step - loss: 0.0229\n",
      "Epoch 6/20\n",
      "22/22 [==============================] - 329s 15s/step - loss: 0.0229\n",
      "Epoch 7/20\n",
      "22/22 [==============================] - 338s 15s/step - loss: 0.0229\n",
      "Epoch 8/20\n",
      "22/22 [==============================] - 339s 15s/step - loss: 0.0229\n",
      "Epoch 9/20\n",
      "22/22 [==============================] - 334s 15s/step - loss: 0.0230\n",
      "Epoch 10/20\n",
      "22/22 [==============================] - 329s 15s/step - loss: 0.0230\n",
      "Epoch 11/20\n",
      "22/22 [==============================] - 344s 16s/step - loss: 0.0229\n",
      "Epoch 12/20\n",
      "22/22 [==============================] - 337s 15s/step - loss: 0.0230\n",
      "Epoch 13/20\n",
      "22/22 [==============================] - 342s 16s/step - loss: 0.0229\n",
      "Epoch 14/20\n",
      "22/22 [==============================] - 346s 16s/step - loss: 0.0229\n",
      "Epoch 15/20\n",
      "22/22 [==============================] - 354s 16s/step - loss: 0.0229\n",
      "Epoch 16/20\n",
      "22/22 [==============================] - 351s 16s/step - loss: 0.0229\n",
      "Epoch 17/20\n",
      "22/22 [==============================] - 354s 16s/step - loss: 0.0230\n",
      "Epoch 18/20\n",
      "22/22 [==============================] - 336s 15s/step - loss: 0.0229\n",
      "Epoch 19/20\n",
      "22/22 [==============================] - 346s 16s/step - loss: 0.0230\n",
      "Epoch 20/20\n",
      "22/22 [==============================] - 346s 16s/step - loss: 0.0229\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd6ed8efd60>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_m1.fit(X_train,y_train,epochs=20,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 5s 747ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred=model_m1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.028100914106030668\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Reshape y_test and y_pred to be 2D arrays\n",
    "y_test_flat = y_test.reshape(y_test.shape[0], -1)\n",
    "y_pred_flat = y_pred.reshape(y_pred.shape[0], -1)\n",
    "\n",
    "\n",
    "\n",
    "mse = mean_squared_error(y_test_flat, y_pred_flat)\n",
    "print(f'Mean Squared Error: {mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......batch_normalization\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "............2\n",
      "............3\n",
      "......batch_normalization_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "............2\n",
      "............3\n",
      "......conv_lstm2d\n",
      ".........cell\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      "...............2\n",
      ".........vars\n",
      "......conv_lstm2d_1\n",
      ".........cell\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      "...............2\n",
      ".........vars\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......flatten\n",
      ".........vars\n",
      "......reshape\n",
      ".........vars\n",
      "...metrics\n",
      "......mean\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........10\n",
      ".........11\n",
      ".........12\n",
      ".........13\n",
      ".........14\n",
      ".........15\n",
      ".........16\n",
      ".........17\n",
      ".........18\n",
      ".........19\n",
      ".........2\n",
      ".........20\n",
      ".........21\n",
      ".........22\n",
      ".........23\n",
      ".........24\n",
      ".........3\n",
      ".........4\n",
      ".........5\n",
      ".........6\n",
      ".........7\n",
      ".........8\n",
      ".........9\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-09-02 12:47:16         4256\n",
      "variables.h5                                   2024-09-02 12:48:40  35797287168\n",
      "metadata.json                                  2024-09-02 12:47:16           64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Model_M1.pkl']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(model_m1,\"Model_M1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "v1rzDJSsij9X"
   },
   "outputs": [],
   "source": [
    "##Combined-Architecture time t0 -> M1 -> M1 -> M1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_excel(\"ftd_temporal_processed.xlsx\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1=[]\n",
    "test2=[]\n",
    "test3=[]\n",
    "test4=[]\n",
    "for i in range(229,287):\n",
    "  y=[]\n",
    "  y.append(i*4+0)\n",
    "  y.append(i*4+1)\n",
    "  y.append(i*4+2)\n",
    "  y.append(i*4+3)\n",
    "  count=0\n",
    "  for j in y:\n",
    "    x1=df.iloc[j]\n",
    "    # print(x1)\n",
    "    # print(x1.index)\n",
    "    ind1=x1['ID']\n",
    "    if(count==0):\n",
    "      test1.append(ind1)\n",
    "    elif(count==1):\n",
    "      test2.append(ind1)\n",
    "    elif(count==2):\n",
    "      test3.append(ind1)\n",
    "    else:\n",
    "      test4.append(ind1)\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_1=[]\n",
    "for i in test1:\n",
    "  s=\"Test2_Version2/ftd_rep1_v2_txt_version2/_\"+i+\"_data.txt\"\n",
    "  img=np.loadtxt(s)\n",
    "#   print(s)\n",
    "  img_1.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_2=[]\n",
    "for i in test2:\n",
    "  s=s=\"Test2_Version2/ftd_rep1_v2_txt_version2/_\"+i+\"_data.txt\"\n",
    "  img=np.loadtxt(s)\n",
    "#   print(s)\n",
    "  img_2.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_3=[]\n",
    "for i in test3:\n",
    "  s=\"Test2_Version2/ftd_rep1_v2_txt_version2/_\"+i+\"_data.txt\"\n",
    "  img=np.loadtxt(s)\n",
    "#   print(s)\n",
    "  img_3.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_4=[]\n",
    "for i in test4:\n",
    "  s=\"Test2_Version2/ftd_rep1_v2_txt_version2/_\"+i+\"_data.txt\"\n",
    "  img=np.loadtxt(s)\n",
    "#   print(s)\n",
    "  img_4.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_1=np.array(img_1)\n",
    "img_2=np.array(img_2)\n",
    "img_3=np.array(img_3)\n",
    "img_4=np.array(img_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_1=img_1.reshape(58, 71*142)\n",
    "img_2=img_2.reshape(58, 71*142)\n",
    "img_3=img_3.reshape(58, 71*142)\n",
    "img_4=img_4.reshape(58, 71*142)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_1=img_1/255.0\n",
    "img_2=img_2/255.0\n",
    "img_3=img_3/255.0\n",
    "img_4=img_4/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58, 10082)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (58, 10082)\n",
      "Model input shape: (None, 1, 71, 142, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Input shape: {img_1.shape}\")\n",
    "print(f\"Model input shape: {model_m1.input_shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_1 = img_1.reshape(58, 1, 71, 142, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7fd6eeb3ad60>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_m1=joblib.load(\"Model_M1.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 22s 1s/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_t2=model_m1.predict(img_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((58, 1, 71, 142, 1), (58, 10082), (58, 10082), (58, 10082))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_1.shape, img_2.shape, img_3.shape, img_4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58, 71, 142)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_t2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_2 = img_2.reshape(58, -1)  # Reshape to (58, 10082) , \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.026774902990415905\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Reshape y_pred_t2 to match img_2\n",
    "y_pred_t2 = y_pred_t2.reshape(58, 71*142)\n",
    "\n",
    "# Calculate mean squared error\n",
    "mse = mean_squared_error(img_2, y_pred_t2)\n",
    "print(\"Mean Squared Error:\", mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For prediction of image 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_t2=y_pred_t2.reshape(58,1,71, 142, 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 2s 783ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_t3=model_m1.predict(y_pred_t2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((58, 71, 142), (58, 10082))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_t3.shape, img_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_3 = img_3.reshape(58, 1, 71, 142, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_t3 = y_pred_t3.reshape(58, 1, 71, 142,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.030238253090135968\n"
     ]
    }
   ],
   "source": [
    "img_3_flat = img_3.flatten()\n",
    "y_pred_t3_flat = y_pred_t3.flatten()\n",
    "mse = mean_squared_error(img_3_flat, y_pred_t3_flat)\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(584756,)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_t3_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_t3_flat=y_pred_t3_flat.reshape(58, 1, 71, 142, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 2s 740ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_t4=model_m1.predict(y_pred_t3_flat) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.09244421746542869\n"
     ]
    }
   ],
   "source": [
    "# Reshape y_pred_t4 to match img_4\n",
    "y_pred_t4 = y_pred_t4.reshape(58, 71*142)\n",
    "# Calculate mean squared error\n",
    "mse = mean_squared_error(img_4, y_pred_t4)\n",
    "print(\"Mean Squared Error:\", mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58, 71, 142)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_t3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_t3=y_pred_t3.reshape(58,1,71,142,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 2s 790ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_t4=model_m1.predict(y_pred_t3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.09244421746542869\n"
     ]
    }
   ],
   "source": [
    "# Reshape y_pred_t4 to match img_4\n",
    "y_pred_t4 = y_pred_t4.reshape(58, 71*142)\n",
    "\n",
    "# Calculate mean squared error\n",
    "mse = mean_squared_error(img_4, y_pred_t4)\n",
    "print(\"Mean Squared Error:\", mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GRUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " time_distributed_2 (TimeDis  (None, 1, 69, 140, 32)   320       \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 1, 69, 140, 32)   128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " time_distributed_3 (TimeDis  (None, 1, 309120)        0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (None, 1, 32)             29678784  \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 1, 32)            128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1, 10082)          332706    \n",
      "                                                                 \n",
      " reshape_1 (Reshape)         (None, 71, 142)           0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 30,012,066\n",
      "Trainable params: 30,011,938\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, GRU, BatchNormalization, Flatten, Dense, Reshape, TimeDistributed\n",
    "\n",
    "model_gru_m1 = Sequential()\n",
    "\n",
    "# Add TimeDistributed Conv2D layers\n",
    "model_gru_m1.add(TimeDistributed(Conv2D(filters=32, kernel_size=(3, 3), activation='relu'), \n",
    "                             input_shape=(1, 71, 142, 1)))\n",
    "model_gru_m1.add(BatchNormalization())\n",
    "\n",
    "# Flatten the Conv2D output\n",
    "model_gru_m1.add(TimeDistributed(Flatten()))\n",
    "\n",
    "# Add GRU layer\n",
    "model_gru_m1.add(GRU(32, return_sequences=True))\n",
    "model_gru_m1.add(BatchNormalization())\n",
    "\n",
    "# Add Dense and Reshape layers\n",
    "model_gru_m1.add(Dense(71 * 142, activation='relu'))\n",
    "model_gru_m1.add(Reshape((71, 142)))\n",
    "\n",
    "# Compile the model\n",
    "model_gru_m1.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "model_gru_m1.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm parametrs -2982991586"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f3c3b2dbee0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_train_function.<locals>.train_function at 0x7f3c3b2dbee0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f3c3b2dbee0> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_train_function.<locals>.train_function at 0x7f3c3b2dbee0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "22/22 [==============================] - 8s 235ms/step - loss: 0.0132\n",
      "Epoch 2/20\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 0.0086\n",
      "Epoch 3/20\n",
      "22/22 [==============================] - 5s 225ms/step - loss: 0.0075\n",
      "Epoch 4/20\n",
      "22/22 [==============================] - 5s 229ms/step - loss: 0.0067\n",
      "Epoch 5/20\n",
      "22/22 [==============================] - 5s 223ms/step - loss: 0.0062\n",
      "Epoch 6/20\n",
      "22/22 [==============================] - 5s 225ms/step - loss: 0.0058\n",
      "Epoch 7/20\n",
      "22/22 [==============================] - 5s 219ms/step - loss: 0.0055\n",
      "Epoch 8/20\n",
      "22/22 [==============================] - 5s 217ms/step - loss: 0.0049\n",
      "Epoch 9/20\n",
      "22/22 [==============================] - 5s 219ms/step - loss: 0.0043\n",
      "Epoch 10/20\n",
      "22/22 [==============================] - 5s 218ms/step - loss: 0.0037\n",
      "Epoch 11/20\n",
      "22/22 [==============================] - 5s 217ms/step - loss: 0.0034\n",
      "Epoch 12/20\n",
      "22/22 [==============================] - 5s 220ms/step - loss: 0.0030\n",
      "Epoch 13/20\n",
      "22/22 [==============================] - 5s 222ms/step - loss: 0.0028\n",
      "Epoch 14/20\n",
      "22/22 [==============================] - 5s 220ms/step - loss: 0.0025\n",
      "Epoch 15/20\n",
      "22/22 [==============================] - 5s 214ms/step - loss: 0.0025\n",
      "Epoch 16/20\n",
      "22/22 [==============================] - 5s 214ms/step - loss: 0.0025\n",
      "Epoch 17/20\n",
      "22/22 [==============================] - 5s 217ms/step - loss: 0.0022\n",
      "Epoch 18/20\n",
      "22/22 [==============================] - 5s 212ms/step - loss: 0.0021\n",
      "Epoch 19/20\n",
      "22/22 [==============================] - 5s 212ms/step - loss: 0.0021\n",
      "Epoch 20/20\n",
      "22/22 [==============================] - 5s 220ms/step - loss: 0.0021\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3af6f139d0>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gru_m1.fit(X_train,y_train,epochs=20,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f3ba579f670> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x7f3ba579f670>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f3ba579f670> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x7f3ba579f670>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "6/6 [==============================] - 1s 40ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred=model_gru_m1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.005379748015358192\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "# Reshape y_test and y_pred to be 2D arrays\n",
    "y_test_flat = y_test.reshape(y_test.shape[0], -1)\n",
    "y_pred_flat = y_pred.reshape(y_pred.shape[0], -1)\n",
    "\n",
    "\n",
    "\n",
    "mse = mean_squared_error(y_test_flat, y_pred_flat)\n",
    "print(f'Mean Squared Error: {mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Combined-Architecture time t0 -> M1 -> M1 -> M1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_excel(\"ftd_temporal_processed.xlsx\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1=[]\n",
    "test2=[]\n",
    "test3=[]\n",
    "test4=[]\n",
    "for i in range(229,287):\n",
    "  y=[]\n",
    "  y.append(i*4+0)\n",
    "  y.append(i*4+1)\n",
    "  y.append(i*4+2)\n",
    "  y.append(i*4+3)\n",
    "  count=0\n",
    "  for j in y:\n",
    "    x1=df.iloc[j]\n",
    "    # print(x1)\n",
    "    # print(x1.index)\n",
    "    ind1=x1['ID']\n",
    "    if(count==0):\n",
    "      test1.append(ind1)\n",
    "    elif(count==1):\n",
    "      test2.append(ind1)\n",
    "    elif(count==2):\n",
    "      test3.append(ind1)\n",
    "    else:\n",
    "      test4.append(ind1)\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_1=[]\n",
    "for i in test1:\n",
    "  s=\"Test2_Version2/ftd_rep1_v2_txt_version2/_\"+i+\"_data.txt\"\n",
    "  img=np.loadtxt(s)\n",
    "#   print(s)\n",
    "  img_1.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_2=[]\n",
    "for i in test2:\n",
    "  s=s=\"Test2_Version2/ftd_rep1_v2_txt_version2/_\"+i+\"_data.txt\"\n",
    "  img=np.loadtxt(s)\n",
    "#   print(s)\n",
    "  img_2.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_3=[]\n",
    "for i in test3:\n",
    "  s=\"Test2_Version2/ftd_rep1_v2_txt_version2/_\"+i+\"_data.txt\"\n",
    "  img=np.loadtxt(s)\n",
    "#   print(s)\n",
    "  img_3.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_4=[]\n",
    "for i in test4:\n",
    "  s=\"Test2_Version2/ftd_rep1_v2_txt_version2/_\"+i+\"_data.txt\"\n",
    "  img=np.loadtxt(s)\n",
    "#   print(s)\n",
    "  img_4.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_1=np.array(img_1)\n",
    "img_2=np.array(img_2)\n",
    "img_3=np.array(img_3)\n",
    "img_4=np.array(img_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_1=img_1.reshape(58, 71*142)\n",
    "img_2=img_2.reshape(58, 71*142)\n",
    "img_3=img_3.reshape(58, 71*142)\n",
    "img_4=img_4.reshape(58, 71*142)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_1=img_1/255.0\n",
    "img_2=img_2/255.0\n",
    "img_3=img_3/255.0\n",
    "img_4=img_4/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (58, 10082)\n",
      "Model input shape: (None, 1, 71, 142, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Input shape: {img_1.shape}\")\n",
    "print(f\"Model input shape: {model_m1.input_shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_1 = img_1.reshape(58, 1, 71, 142, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 30ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_t2=model_gru_m1.predict(img_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((58, 1, 71, 142, 1), (58, 10082), (58, 10082), (58, 10082))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_1.shape, img_2.shape, img_3.shape, img_4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.005062973071437736\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Reshape y_pred_t2 to match img_2\n",
    "y_pred_t2 = y_pred_t2.reshape(58, 71*142)\n",
    "\n",
    "# Calculate mean squared error\n",
    "mse = mean_squared_error(img_2, y_pred_t2)\n",
    "print(\"Mean Squared Error:\", mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For prediction of image 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_t2=y_pred_t2.reshape(58,1,71, 142, 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 38ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_t3=model_gru_m1.predict(y_pred_t2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.0064836388685062625\n"
     ]
    }
   ],
   "source": [
    "img_3_flat = img_3.flatten()\n",
    "y_pred_t3_flat = y_pred_t3.flatten()\n",
    "mse = mean_squared_error(img_3_flat, y_pred_t3_flat)\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For prediction of image 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_t3_flat=y_pred_t3_flat.reshape(58, 1, 71, 142, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 25ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_t4=model_gru_m1.predict(y_pred_t3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.008263281573454854\n"
     ]
    }
   ],
   "source": [
    "# Reshape y_pred_t4 to match img_4\n",
    "y_pred_t4 = y_pred_t4.reshape(58, 71*142)\n",
    "\n",
    "# Calculate mean squared error\n",
    "mse = mean_squared_error(img_4, y_pred_t4)\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......batch_normalization\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "............2\n",
      "............3\n",
      "......batch_normalization_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "............2\n",
      "............3\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......gru\n",
      ".........cell\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      "...............2\n",
      ".........vars\n",
      "......reshape\n",
      ".........vars\n",
      "......time_distributed\n",
      ".........layer\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      ".........vars\n",
      "......time_distributed_1\n",
      ".........layer\n",
      "............vars\n",
      ".........vars\n",
      "...metrics\n",
      "......mean\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........10\n",
      ".........11\n",
      ".........12\n",
      ".........13\n",
      ".........14\n",
      ".........15\n",
      ".........16\n",
      ".........17\n",
      ".........18\n",
      ".........19\n",
      ".........2\n",
      ".........20\n",
      ".........21\n",
      ".........22\n",
      ".........3\n",
      ".........4\n",
      ".........5\n",
      ".........6\n",
      ".........7\n",
      ".........8\n",
      ".........9\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2024-09-03 11:49:17         4011\n",
      "variables.h5                                   2024-09-03 11:49:17    360186296\n",
      "metadata.json                                  2024-09-03 11:49:17           64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Model_GRU_M1.pkl']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(model_gru_m1,\"Model_GRU_M1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN2D-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " time_distributed_2 (TimeDi  (None, 1, 69, 140, 32)    320       \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 1, 69, 140, 32)    128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " time_distributed_3 (TimeDi  (None, 1, 309120)         0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 1, 32)             39571584  \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 1, 32)             128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1, 10082)          332706    \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 71, 142)           0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 39904866 (152.22 MB)\n",
      "Trainable params: 39904738 (152.22 MB)\n",
      "Non-trainable params: 128 (512.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, GRU, LSTM, BatchNormalization, Flatten, Dense, Reshape, TimeDistributed\n",
    "\n",
    "model_lstm_m1 = Sequential()\n",
    "\n",
    "# Add TimeDistributed Conv2D layers\n",
    "model_lstm_m1.add(TimeDistributed(Conv2D(filters=32, kernel_size=(3, 3), activation='relu'), \n",
    "                             input_shape=(1, 71, 142, 1)))\n",
    "model_lstm_m1.add(BatchNormalization())\n",
    "\n",
    "# Flatten the Conv2D output\n",
    "model_lstm_m1.add(TimeDistributed(Flatten()))\n",
    "\n",
    "# Add LSTM layer\n",
    "model_lstm_m1.add(LSTM(32, return_sequences=True))\n",
    "model_lstm_m1.add(BatchNormalization())\n",
    "\n",
    "# Add Dense and Reshape layers\n",
    "model_lstm_m1.add(Dense(71 * 142, activation='relu'))\n",
    "model_lstm_m1.add(Reshape((71, 142)))\n",
    "\n",
    "# Compile the model\n",
    "model_lstm_m1.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "model_lstm_m1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "22/22 [==============================] - 9s 287ms/step - loss: 0.0131\n",
      "Epoch 2/20\n",
      "22/22 [==============================] - 7s 299ms/step - loss: 0.0085\n",
      "Epoch 3/20\n",
      "22/22 [==============================] - 6s 273ms/step - loss: 0.0074\n",
      "Epoch 4/20\n",
      "22/22 [==============================] - 6s 272ms/step - loss: 0.0065\n",
      "Epoch 5/20\n",
      "22/22 [==============================] - 6s 274ms/step - loss: 0.0061\n",
      "Epoch 6/20\n",
      "22/22 [==============================] - 6s 275ms/step - loss: 0.0053\n",
      "Epoch 7/20\n",
      "22/22 [==============================] - 6s 271ms/step - loss: 0.0049\n",
      "Epoch 8/20\n",
      "22/22 [==============================] - 6s 265ms/step - loss: 0.0046\n",
      "Epoch 9/20\n",
      "22/22 [==============================] - 6s 269ms/step - loss: 0.0040\n",
      "Epoch 10/20\n",
      "22/22 [==============================] - 6s 269ms/step - loss: 0.0035\n",
      "Epoch 11/20\n",
      "22/22 [==============================] - 6s 273ms/step - loss: 0.0032\n",
      "Epoch 12/20\n",
      "22/22 [==============================] - 6s 266ms/step - loss: 0.0028\n",
      "Epoch 13/20\n",
      "22/22 [==============================] - 6s 271ms/step - loss: 0.0026\n",
      "Epoch 14/20\n",
      "22/22 [==============================] - 6s 265ms/step - loss: 0.0025\n",
      "Epoch 15/20\n",
      "22/22 [==============================] - 6s 267ms/step - loss: 0.0026\n",
      "Epoch 16/20\n",
      "22/22 [==============================] - 6s 262ms/step - loss: 0.0026\n",
      "Epoch 17/20\n",
      "22/22 [==============================] - 6s 272ms/step - loss: 0.0026\n",
      "Epoch 18/20\n",
      "22/22 [==============================] - 6s 267ms/step - loss: 0.0024\n",
      "Epoch 19/20\n",
      "22/22 [==============================] - 6s 264ms/step - loss: 0.0023\n",
      "Epoch 20/20\n",
      "22/22 [==============================] - 6s 263ms/step - loss: 0.0022\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7efa80419610>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lstm_m1.fit(X_train,y_train,epochs=20,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 1s 42ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred=model_lstm_m1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.004614525214203687\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "# Reshape y_test and y_pred to be 2D arrays\n",
    "y_test_flat = y_test.reshape(y_test.shape[0], -1)\n",
    "y_pred_flat = y_pred.reshape(y_pred.shape[0], -1)\n",
    "\n",
    "\n",
    "\n",
    "mse = mean_squared_error(y_test_flat, y_pred_flat)\n",
    "print(f'Mean Squared Error: {mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Combined-Architecture time t0 -> M1 -> M1 -> M1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_excel(\"ftd_temporal_processed.xlsx\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1=[]\n",
    "test2=[]\n",
    "test3=[]\n",
    "test4=[]\n",
    "for i in range(229,287):\n",
    "  y=[]\n",
    "  y.append(i*4+0)\n",
    "  y.append(i*4+1)\n",
    "  y.append(i*4+2)\n",
    "  y.append(i*4+3)\n",
    "  count=0\n",
    "  for j in y:\n",
    "    x1=df.iloc[j]\n",
    "    # print(x1)\n",
    "    # print(x1.index)\n",
    "    ind1=x1['ID']\n",
    "    if(count==0):\n",
    "      test1.append(ind1)\n",
    "    elif(count==1):\n",
    "      test2.append(ind1)\n",
    "    elif(count==2):\n",
    "      test3.append(ind1)\n",
    "    else:\n",
    "      test4.append(ind1)\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_1=[]\n",
    "for i in test1:\n",
    "  s=\"Test2_Version2/ftd_rep1_v2_txt_version2/_\"+i+\"_data.txt\"\n",
    "  img=np.loadtxt(s)\n",
    "#   print(s)\n",
    "  img_1.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_2=[]\n",
    "for i in test2:\n",
    "  s=s=\"Test2_Version2/ftd_rep1_v2_txt_version2/_\"+i+\"_data.txt\"\n",
    "  img=np.loadtxt(s)\n",
    "#   print(s)\n",
    "  img_2.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_3=[]\n",
    "for i in test3:\n",
    "  s=\"Test2_Version2/ftd_rep1_v2_txt_version2/_\"+i+\"_data.txt\"\n",
    "  img=np.loadtxt(s)\n",
    "#   print(s)\n",
    "  img_3.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_4=[]\n",
    "for i in test4:\n",
    "  s=\"Test2_Version2/ftd_rep1_v2_txt_version2/_\"+i+\"_data.txt\"\n",
    "  img=np.loadtxt(s)\n",
    "#   print(s)\n",
    "  img_4.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_1=np.array(img_1)\n",
    "img_2=np.array(img_2)\n",
    "img_3=np.array(img_3)\n",
    "img_4=np.array(img_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_1=img_1.reshape(58, 71*142)\n",
    "img_2=img_2.reshape(58, 71*142)\n",
    "img_3=img_3.reshape(58, 71*142)\n",
    "img_4=img_4.reshape(58, 71*142)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_1=img_1/255.0\n",
    "img_2=img_2/255.0\n",
    "img_3=img_3/255.0\n",
    "img_4=img_4/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (58, 1, 71, 142, 1)\n",
      "Model input shape: (None, 1, 71, 142, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Input shape: {img_1.shape}\")\n",
    "print(f\"Model input shape: {model_lstm_m1.input_shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_1 = img_1.reshape(58, 1, 71, 142, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 29ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_t2=model_lstm_m1.predict(img_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((58, 1, 71, 142, 1), (58, 10082), (58, 10082), (58, 10082))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_1.shape, img_2.shape, img_3.shape, img_4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.004009040544987586\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Reshape y_pred_t2 to match img_2\n",
    "y_pred_t2 = y_pred_t2.reshape(58, 71*142)\n",
    "\n",
    "# Calculate mean squared error\n",
    "mse = mean_squared_error(img_2, y_pred_t2)\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For prediction of image 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_t2=y_pred_t2.reshape(58,1,71, 142, 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 24ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_t3=model_lstm_m1.predict(y_pred_t2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.005198576086006672\n"
     ]
    }
   ],
   "source": [
    "img_3_flat = img_3.flatten()\n",
    "y_pred_t3_flat = y_pred_t3.flatten()\n",
    "mse = mean_squared_error(img_3_flat, y_pred_t3_flat)\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For prediction of image 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_t3_flat=y_pred_t3_flat.reshape(58, 1, 71, 142, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 23ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_t4=model_lstm_m1.predict(y_pred_t3_flat) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.007014438702887822\n"
     ]
    }
   ],
   "source": [
    "# Reshape y_pred_t4 to match img_4\n",
    "y_pred_t4 = y_pred_t4.reshape(58, 71*142)\n",
    "\n",
    "# Calculate mean squared error\n",
    "mse = mean_squared_error(img_4, y_pred_t4)\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Model_LSTM_M1.pkl']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(model_lstm_m1,\"Model_LSTM_M1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
